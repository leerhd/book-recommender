{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Import Modules and Load Data Files",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nfrom surprise import NormalPredictor, BaselineOnly, KNNBaseline, KNNWithMeans, Reader, Dataset, accuracy, dump\nfrom surprise.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/book-ratings/ratings.csv\n/kaggle/input/book-ratings/books.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Read CSV files into dataframes\nbooks = pd.read_csv('../input/book-ratings/books.csv')\nratings = pd.read_csv('../input/book-ratings/ratings.csv')",
   "metadata": {
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Clean Data Sets\nWe will remove books with duplicate tiles and drop books titles that contain non-Latin characters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# See which variables have missing values\nbooks.isnull().sum(axis=0)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "execution_count": 3,
     "output_type": "execute_result",
     "data": {
      "text/plain": "book_id                         0\ngoodreads_book_id               0\nbest_book_id                    0\nwork_id                         0\nbooks_count                     0\nisbn                          700\nisbn13                        585\nauthors                         0\noriginal_publication_year      21\noriginal_title                585\ntitle                           0\nlanguage_code                1084\naverage_rating                  0\nratings_count                   0\nwork_ratings_count              0\nwork_text_reviews_count         0\nratings_1                       0\nratings_2                       0\nratings_3                       0\nratings_4                       0\nratings_5                       0\nimage_url                       0\nsmall_image_url                 0\ndtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Print descriptive statistics for ratings data\nratings.describe()",
   "metadata": {
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            user_id       book_id        rating\ncount  5.976479e+06  5.976479e+06  5.976479e+06\nmean   2.622446e+04  2.006477e+03  3.919866e+00\nstd    1.541323e+04  2.468499e+03  9.910868e-01\nmin    1.000000e+00  1.000000e+00  1.000000e+00\n25%    1.281300e+04  1.980000e+02  3.000000e+00\n50%    2.593800e+04  8.850000e+02  4.000000e+00\n75%    3.950900e+04  2.973000e+03  5.000000e+00\nmax    5.342400e+04  1.000000e+04  5.000000e+00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.976479e+06</td>\n      <td>5.976479e+06</td>\n      <td>5.976479e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.622446e+04</td>\n      <td>2.006477e+03</td>\n      <td>3.919866e+00</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.541323e+04</td>\n      <td>2.468499e+03</td>\n      <td>9.910868e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.281300e+04</td>\n      <td>1.980000e+02</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.593800e+04</td>\n      <td>8.850000e+02</td>\n      <td>4.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.950900e+04</td>\n      <td>2.973000e+03</td>\n      <td>5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.342400e+04</td>\n      <td>1.000000e+04</td>\n      <td>5.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Drop duplicate book titles\nbooks = books.drop_duplicates(subset=['title'])",
   "metadata": {
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def is_english(s):\n    try:\n        s.encode(encoding='utf-8').decode('ascii')\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True\n\n# Drop books with titles that contain non-Latin characters\nbooks = books[books['title'].apply(is_english)]\n\n# Drop user ratings that correspond to books with titles that contain non-Latin characters\nratings = ratings[ratings['book_id'].isin(books['book_id'].tolist())]",
   "metadata": {
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Create Training and Test Data Sets\nWe will use a 80/20 split for the training and test sets",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Reader class to define the structure of the ratings file\nreader = Reader(rating_scale=(1, 5))\n\n# Read dataframe into the Dataset class\nbook_data = Dataset.load_from_df(ratings[['user_id', 'book_id', 'rating']], reader)\n\n# Split the data into a training and testing set using an 80/20 split\ntrain_set, test_set = train_test_split(book_data, test_size=0.2)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Model Fitting and Parameter Adjustment",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "norm = NormalPredictor()\nnorm.fit(train_set)\nnorm_pred = norm.test(test_set)\naccuracy.rmse(norm_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "RMSE: 1.3230\n",
     "output_type": "stream"
    },
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.323036569665345"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "baseline = BaselineOnly(bsl_options = {'method': 'als'})\nbaseline.fit(train_set)\nbaseline_pred = baseline.test(test_set)\naccuracy.rmse(baseline_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "Estimating biases using als...\nRMSE: 0.8549\n",
     "output_type": "stream"
    },
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8548847840711998"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "als_model = KNNBaseline(k=40, sim_options={'name': 'pearson_baseline', 'user_based': False}, bsl_options = {'method': 'als'})\nals_model.fit(train_set)\nals_pred = als_model.test(test_set)\naccuracy.rmse(als_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Estimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nRMSE: 0.7970\n",
     "output_type": "stream"
    },
    {
     "execution_count": 10,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7969910311736281"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "sgd_model = KNNBaseline(k=40, sim_options={'name': 'pearson_baseline', 'user_based': False}, bsl_options = {'method': 'sgd'})\nsgd_model.fit(train_set)\nsgd_pred = sgd_model.test(test_set)\naccuracy.rmse(sgd_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "Estimating biases using sgd...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nRMSE: 0.7973\n",
     "output_type": "stream"
    },
    {
     "execution_count": 11,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7972748523750234"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "als_model = KNNBaseline(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False}, bsl_options = {'method': 'als'})\nals_model.fit(train_set)\nals_pred = als_model.test(test_set)\naccuracy.rmse(als_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "Estimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nRMSE: 0.7959\n",
     "output_type": "stream"
    },
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7958647039682978"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "sgd_model = KNNBaseline(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False}, bsl_options = {'method': 'sgd'})\nsgd_model.fit(train_set)\nsgd_pred = sgd_model.test(test_set)\naccuracy.rmse(sgd_pred)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "Estimating biases using sgd...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nRMSE: 0.7963\n",
     "output_type": "stream"
    },
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7962780858648439"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Save the model so we can resuse in our application\ndump.dump('/kaggle/working/item_model', algo=als_model)",
   "metadata": {
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  }
 ]
}